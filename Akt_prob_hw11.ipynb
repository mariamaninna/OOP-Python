{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_tkk20a69In"
   },
   "source": [
    "В семинаре мы работали с датасетами инструкций alpaca и dolly. Они англоязычные. В домашке вам нужно создать аналогичный датасет на русском языке и обучить аналогичную модель на этом датасете. В качестве итогового результата у вас должна получится модель, которая может связно отвечать на русскоязычные инструкции на русском языке. Приведите как минимум три разных примера. Правильность ответов не так важна, так как вы скорее всего будете использовать небольшие модели, но текст должен быть не рандомным.\n",
    "\n",
    "Русскоязычный датасет инструкций должен быть больше 5 тысяч примеров. Он может быть основнован на alpaca/dolly (например, вы можете просто прогнать все через переводную модель, которая была на семинаре, или даже google translate). Или вы можете придумать способ создать аналогичный датасет каким-то другим способом (переделать открытые датасеты с помощью правил). Датасет может быть не уникальным, можно скооперироваться с одногруппниками и сделать один датасет на всех.\n",
    "\n",
    "Вы можете попробовать дообучать любую небольшую decoder-only модель. Скорее всего лучше всего будут работать модели, изначально обученные на русском языке (rugpt например). Но возможно даже модели вроде opt можно будет дообучить на русскоязычных инструкциях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qK1xeRlSA4Zf",
    "outputId": "c75547a7-0ec6-41a2-94a6-0321aa3c128e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests==2.31 in ./venv/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests==2.31) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests==2.31) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests==2.31) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests==2.31) (3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests==2.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDm6LyL8C82w",
    "outputId": "77b36974-20ec-42cc-9f48-1f8c46b69845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zstandard in ./venv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: jsonlines in ./venv/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./venv/lib/python3.10/site-packages (from jsonlines) (23.2.0)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from datasets) (3.13.4)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./venv/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./venv/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in ./venv/lib/python3.10/site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./venv/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./venv/lib/python3.10/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aslyutikov/Masha/venv/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for IlyaGusev/ru_turbo_alpaca contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/IlyaGusev/ru_turbo_alpaca\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install zstandard jsonlines datasets\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"IlyaGusev/ru_turbo_alpaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mhUDSUo32t5",
    "outputId": "eaf03904-3eb3-4f29-fa3a-ffacb12d7503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.1 in ./venv/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (11.7.4.91)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (11.7.101)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (11.4.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (2.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (3.3)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch==2.0.1) (3.13.4)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (59.6.0)\n",
      "Requirement already satisfied: lit in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1) (18.1.4)\n",
      "Requirement already satisfied: cmake in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1) (3.29.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch==2.0.1) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.40.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./venv/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RKnqHraAweS2"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "import transformers\n",
    "import copy\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbuM6PhZ-WmB",
    "outputId": "391e7034-1b75-440e-f5e6-5515dd0c1207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (0.29.3)\n",
      "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: triton==2.0.0 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.43.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (59.6.0)\n",
      "Requirement already satisfied: lit in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (18.1.4)\n",
      "Requirement already satisfied: cmake in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.29.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "if3CK9h5Bb6o",
    "outputId": "fff5d403-d0a1-4a07-d62d-28e932195887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.29.3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import accelerate\n",
    "accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ay_vKR-xB3JK",
    "outputId": "2fb5304d-4fb9-4f5b-ec77-5faf56dfd6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in ./venv/lib/python3.10/site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers[torch]) (3.13.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (2024.4.28)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./venv/lib/python3.10/site-packages (from transformers[torch]) (0.29.3)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (11.7.101)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: triton==2.0.0 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (2.0.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->transformers[torch]) (59.6.0)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->transformers[torch]) (0.43.0)\n",
      "Requirement already satisfied: lit in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch->transformers[torch]) (18.1.4)\n",
      "Requirement already satisfied: cmake in ./venv/lib/python3.10/site-packages (from triton==2.0.0->torch->transformers[torch]) (3.29.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers[torch]) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ie03wuvWrr0q",
    "outputId": "ab203601-9d40-4eb9-f58c-75fc31deab31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Опиши процесс изготовления торта. Укажи ингредиенты, необходимые для этого.',\n",
       " 'input': '',\n",
       " 'output': 'Для изготовления торта необходимы следующие ингредиенты: мука, сахар, яйца, молоко, сливочное масло, разрыхлитель, ванилин. Сначала нужно смешать муку с сахаром и добавить яйца, молоко, разрыхлитель и ваниль. Затем тесто надо хорошо перемешать и разделить на несколько частей. Каждую часть нужно запекать в духовке до готовности. После этого торт надо собрать, сложив слои пирога вместе с начинкой и украшениями.',\n",
       " 'alternative_output': 'Для изготовления торта необходимо следующее:\\n\\nИнгредиенты для теста:\\n\\n- Мука\\n- Сахар\\n- Яйца\\n- Растительное масло или сливочное масло\\n- Разрыхлитель, как правило, это порошок для выпечки\\n- Молоко\\n\\nИнгредиенты для крема:\\n\\n- Сливочное масло\\n- Сахарная пудра\\n- Ванилин или другой ароматизатор\\n- Молоко или сливки\\n- Фрукты или ягоды (если используются)\\n\\nШаги изготовления торта:\\n\\n1. Для теста смешайте муку, сахар и разрыхлитель в одной большой миске.\\n\\n2. Отдельно взбейте яйца и добавьте их в миску с сухими ингредиентами. Постепенно добавляйте молоко и масло.\\n\\n3. Вылейте тесто в разогретую духовку и испеките до золотистой корочки.\\n\\n4. Для крема взбейте сливочное масло, добавьте сахарную пудру и ароматизатор. Если крем слишком густой, добавьте молоко или сливки.\\n\\n5. Разрежьте торт на две части и налейте крем между слоями. Украсьте торт фруктами или ягодами.\\n\\n6. Находите уютное место и наслаждайтесь вкусом своего торта.',\n",
       " 'label': None,\n",
       " 'all_labels': [],\n",
       " 'agreement': None,\n",
       " 'overlap': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN8009Fks0H5"
   },
   "source": [
    "Код с пары (но русскоязычный промпт):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zU35_M4_szoP"
   },
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Ниже представлена инструкция с описанием задания, а также входные данные с дополнительной информацией. \"\n",
    "        \"Напишите подходящий ответ на запрос.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Ниже представлена инструкция с описанием задания. \"\n",
    "        \"Напишите подходящий ответ на запрос.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mmJ8SorGwZiL"
   },
   "outputs": [],
   "source": [
    "def _tokenize_fn(strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "    \"\"\"Tokenize a list of strings.\"\"\"\n",
    "    tokenized_list = [\n",
    "        tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "        for text in strings\n",
    "    ]\n",
    "    input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "    input_ids_lens = labels_lens = [\n",
    "        tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "    ]\n",
    "    return dict(\n",
    "        input_ids=input_ids,\n",
    "        labels=labels,\n",
    "        input_ids_lens=input_ids_lens,\n",
    "        labels_lens=labels_lens,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A5-NnnzrwpOW"
   },
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    sources: Sequence[str],\n",
    "    targets: Sequence[str],\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    ") -> Dict:\n",
    "    \"\"\"Preprocess the data by tokenizing.\"\"\"\n",
    "    examples = [s + t for s, t in zip(sources, targets)]\n",
    "    examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
    "    input_ids = examples_tokenized[\"input_ids\"]\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "    for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "        label[:source_len] = IGNORE_INDEX\n",
    "    return dict(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lBZ0bFfsw3xT"
   },
   "outputs": [],
   "source": [
    "class SupervisedDataset(Dataset):\n",
    "    \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer: transformers.PreTrainedTokenizer):\n",
    "        super(SupervisedDataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "        list_data_dict = data[\"train\"]\n",
    "\n",
    "        logging.warning(\"Formatting inputs...\")\n",
    "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
    "        sources = [\n",
    "            prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
    "            for example in list_data_dict\n",
    "        ]\n",
    "        targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
    "\n",
    "        logging.warning(\"Tokenizing inputs... This may take some time...\")\n",
    "        data_dict = preprocess(sources, targets, tokenizer)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNAKZMDG2j1R",
    "outputId": "15b807ac-bf68-47c9-d861-4e8676d7a816"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aslyutikov/Masha/venv/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        max_length=512,\n",
    "        cache_dir=\"huggingface_cache\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KViXzhiM2ohB"
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=\"huggingface_cache\",\n",
    "    model_max_length=512,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "he75zOZ-2_r9",
    "outputId": "eb3fb66a-5418-41a0-8f8e-314d37447ea4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Formatting inputs...\n",
      "WARNING:root:Tokenizing inputs... This may take some time...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SupervisedDataset(tokenizer=tokenizer, data=dataset)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OxR7Og3H3TGB"
   },
   "outputs": [],
   "source": [
    "train_args = transformers.TrainingArguments(learning_rate=1e-5,\n",
    "                 num_train_epochs=2,\n",
    "                 per_device_train_batch_size=2,\n",
    "                 gradient_accumulation_steps=1,\n",
    "                 evaluation_strategy='no',\n",
    "                 weight_decay=0.,\n",
    "                 warmup_ratio=0.03,\n",
    "                 lr_scheduler_type=\"cosine\",\n",
    "                 save_strategy='no',\n",
    "                 logging_steps=1000,\n",
    "                 output_dir=\"opt125_instruct_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-tMBSZr23UW3"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                 tokenizer=tokenizer,\n",
    "                 args=train_args,\n",
    "                 train_dataset=train_dataset,\n",
    "                 eval_dataset=None,\n",
    "                 data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "Z1y8EZ_u6aM4",
    "outputId": "84e31ff3-1f7b-48a2-e1ad-ba1d940a4795"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29822' max='29822' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29822/29822 53:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.296100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.196200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.058600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.998300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.989700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.969200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.965100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.916600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.911300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.902900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.892200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.891700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.889400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.885400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.884200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.885700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=29822, training_loss=0.9736383548245633, metrics={'train_runtime': 3205.6547, 'train_samples_per_second': 18.606, 'train_steps_per_second': 9.303, 'total_flos': 1.4688052883712e+16, 'train_loss': 0.9736383548245633, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pBD8cdpTkS_W"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('opt125_ft_02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fDYE8-0FkbBj"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "MODEL_NAME = 'opt125_ft_02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XHC2fasxkfBv"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, model_max_length=512, max_length=512)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeBcey9-lFPV"
   },
   "source": [
    "Демонстрация работы модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lbaS6JaTktBa"
   },
   "outputs": [],
   "source": [
    "def predict_for_instruction(instruction, text, model):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    prompt = (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "              \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "              f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{text}\\n\\n### Response:\")\n",
    "\n",
    "    inputs = tokenizer([prompt],\n",
    "                        return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "        temperature=0.4,\n",
    "        max_length=1000,\n",
    "        no_repeat_ngram_size=15,\n",
    "        repetition_penalty= 0.5,\n",
    "        early_stopping=False,\n",
    "        num_return_sequences= 1,\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        do_sample=True,\n",
    "    )\n",
    "    summaries = tokenizer.batch_decode(output_sequences[:,len(inputs[0]):], skip_special_tokens=False)\n",
    "    return summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HFhV0o9ok3NZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aslyutikov/Masha/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1256: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'x = 4</s>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Решите уравнение, найдите x\"\n",
    "text = \"2x - 4 = 0\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Fc6tIeqklG0Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'любви прошение о любви прошее обработке прошенип прошенип приростности.</s>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Напишите короткое сочинение о любви\"\n",
    "text = \"\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "sxwi8xullsXc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Какие сегодня чичели?</s>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Какое сегодня число?\"\n",
    "text = \"\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JfXQqcTQm3X2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Муха села находится варенье.</s>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Продолжите стихотворение\"\n",
    "text = \"Муха села на варенье\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tvLkBuajnIxp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Начника на работу мобильно помогает мне расслабитьсь на прошлом гомаде на работе. Начника начника помогает мне помочь начать с прошлого гомада на работе, но она помогает мне улучшить нашу гомаду на работе. Но она помогает улучшить н Travis, Travis начника, следует привести от работы на работе.</s>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Напиши письмо начальнику, сообщающее о том, что ты опаздываешь на работу\"\n",
    "text = \"\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
